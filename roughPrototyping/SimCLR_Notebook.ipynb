{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimCLR Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae830dbb238f4dffae4e036c9bf45d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_503e393caa2742b6b138123b9825f5fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39d9308bad1d43cfa514fbb42edd9327",
              "IPY_MODEL_25bf9bc3a6b74f3197b362b6fa96bc21"
            ]
          }
        },
        "503e393caa2742b6b138123b9825f5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39d9308bad1d43cfa514fbb42edd9327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67e9a595c837461786be105ab20432c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3ad34d627cb497eac018e09832ee77f"
          }
        },
        "25bf9bc3a6b74f3197b362b6fa96bc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36ac096b17084423851248ccc373d64a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2640404480/? [04:10&lt;00:00, 10847837.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa750903fe2c4987bb5ec8be771fb3cb"
          }
        },
        "67e9a595c837461786be105ab20432c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3ad34d627cb497eac018e09832ee77f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36ac096b17084423851248ccc373d64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa750903fe2c4987bb5ec8be771fb3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF8ZoVrwt0n0",
        "colab_type": "text"
      },
      "source": [
        "# SimCLR\n",
        "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer.\n",
        "\n",
        "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt6WMxjCvN3o",
        "colab_type": "text"
      },
      "source": [
        "## Setup the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53JMIYtat8tT",
        "colab_type": "code",
        "outputId": "d4d0b08a-553e-45c2-e65a-7d06f5d8967d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/spijkervet/SimCLR.git\n",
        "%cd SimCLR\n",
        "!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
        "!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
        "!pip install  pyyaml --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SimCLR' already exists and is not an empty directory.\n",
            "/content/SimCLR\n",
            "--2020-04-19 06:00:30--  https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200419%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200419T060005Z&X-Amz-Expires=300&X-Amz-Signature=ce2efe4ccc17f59f38c1d180a548b69cf7011831d5372ea79504e91bbd791302&X-Amz-SignedHeaders=host&actor_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-04-19 06:00:30--  https://github-production-release-asset-2e65be.s3.amazonaws.com/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200419%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200419T060005Z&X-Amz-Expires=300&X-Amz-Signature=ce2efe4ccc17f59f38c1d180a548b69cf7011831d5372ea79504e91bbd791302&X-Amz-SignedHeaders=host&actor_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.96.99\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.96.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111607632 (106M) [application/octet-stream]\n",
            "Saving to: ‘checkpoint_100.tar.2’\n",
            "\n",
            "checkpoint_100.tar. 100%[===================>] 106.44M  81.2MB/s    in 1.3s    \n",
            "\n",
            "2020-04-19 06:00:31 (81.2 MB/s) - ‘checkpoint_100.tar.2’ saved [111607632/111607632]\n",
            "\n",
            "setup.sh: 2: setup.sh: conda: not found\n",
            "setup.sh: 2: setup.sh: conda: not found\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: sacred in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.6.0.post3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: py-cpuinfo>=4.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (5.0.0)\n",
            "Requirement already satisfied: munch<3.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (20.3)\n",
            "Requirement already satisfied: jsonpickle<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (1.4)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=18.0->sacred->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle<2.0,>=1.2->sacred->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython->sacred->-r requirements.txt (line 4)) (4.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle<2.0,>=1.2->sacred->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython->sacred->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already up-to-date: pyyaml in /usr/local/lib/python3.6/dist-packages (5.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ3jq3cWynLf",
        "colab_type": "text"
      },
      "source": [
        "# Part 1:\n",
        "## SimCLR pre-training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jhAv3hv8IHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n",
        "use_tpu = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwW10d2O7pn8",
        "colab_type": "text"
      },
      "source": [
        "#### Install PyTorch/XLA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj84aiC27oxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_tpu:\n",
        "  VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT6sJkCKYyBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install torch_xla"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNDRcPbbymlX",
        "colab_type": "code",
        "outputId": "4dc106ff-4fe7-49fd-ae3d-a3f847f0063b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "if use_tpu:\n",
        "  # imports the torch_xla package for TPU support\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "  dev = xm.xla_device()\n",
        "  print(dev)\n",
        "  \n",
        "import torchvision\n",
        "import argparse\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "apex = False\n",
        "try:\n",
        "    from apex import amp\n",
        "    apex = True\n",
        "except ImportError:\n",
        "    print(\n",
        "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
        "    )\n",
        "\n",
        "from model import load_model, save_model\n",
        "from modules import NT_Xent\n",
        "from modules.transformations import TransformsSimCLR\n",
        "from utils import mask_correlated_samples, post_config_hook\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abk6aFZxyedW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, train_loader, model, criterion, optimizer, writer):\n",
        "    loss_epoch = 0\n",
        "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x_i = x_i.to(args.device)\n",
        "        x_j = x_j.to(args.device)\n",
        "\n",
        "        # positive pair, with encoding\n",
        "        h_i, z_i = model(x_i)\n",
        "        h_j, z_j = model(x_j)\n",
        "\n",
        "        loss = criterion(z_i, z_j)\n",
        "\n",
        "        if apex and args.fp16:\n",
        "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                scaled_loss.backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
        "\n",
        "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
        "        loss_epoch += loss.item()\n",
        "        args.global_step += 1\n",
        "\n",
        "    return loss_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYbV0fa_y03Z",
        "colab_type": "text"
      },
      "source": [
        "### Load arguments from `config/config.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1klUf-IuyxdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "from utils.yaml_config_hook import yaml_config_hook\n",
        "\n",
        "config = yaml_config_hook(\"./config/config.yaml\")\n",
        "args = argparse.Namespace(**config)\n",
        "\n",
        "if use_tpu:\n",
        "  args.device = dev\n",
        "else:\n",
        "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "args.out_dir = \"logs\"\n",
        "if not os.path.exists(\"logs\"):\n",
        "  os.makedirs(\"logs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O86__UhA0Lvr",
        "colab_type": "code",
        "outputId": "4a1a8616-07ff-4c22-d617-104e4c6b5dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
        "args.batch_size = 64\n",
        "args.resnet = \"resnet18\"\n",
        "pprint(vars(args))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 64,\n",
            " 'dataset': 'STL10',\n",
            " 'device': device(type='cuda', index=0),\n",
            " 'epoch_num': 100,\n",
            " 'epochs': 100,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'logistic_batch_size': 256,\n",
            " 'logistic_epochs': 100,\n",
            " 'model_path': 'logs/0',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'out_dir': 'logs',\n",
            " 'projection_dim': 64,\n",
            " 'resnet': 'resnet18',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJfeOM9PzNoF",
        "colab_type": "text"
      },
      "source": [
        "### Load dataset into train loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGcskdBsytbj",
        "colab_type": "code",
        "outputId": "1f48d103-8345-4c7b-c254-e662f2d27b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "ae830dbb238f4dffae4e036c9bf45d6c",
            "503e393caa2742b6b138123b9825f5fd",
            "39d9308bad1d43cfa514fbb42edd9327",
            "25bf9bc3a6b74f3197b362b6fa96bc21",
            "67e9a595c837461786be105ab20432c1",
            "e3ad34d627cb497eac018e09832ee77f",
            "36ac096b17084423851248ccc373d64a",
            "aa750903fe2c4987bb5ec8be771fb3cb"
          ]
        }
      },
      "source": [
        "root = \"./datasets\"\n",
        "\n",
        "train_sampler = None\n",
        "\n",
        "if args.dataset == \"STL10\":\n",
        "    train_dataset = torchvision.datasets.STL10(\n",
        "        root, split=\"unlabeled\", download=True, transform=TransformsSimCLR()\n",
        "    )\n",
        "elif args.dataset == \"CIFAR10\":\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root, download=True, transform=TransformsSimCLR()\n",
        "    )\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=(train_sampler is None),\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        "    sampler=train_sampler,\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./datasets/stl10_binary.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae830dbb238f4dffae4e036c9bf45d6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./datasets/stl10_binary.tar.gz to ./datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBlXZwvjzPmp",
        "colab_type": "text"
      },
      "source": [
        "### Load the SimCLR model, optimizer and learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERq_yHSzJRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, optimizer, scheduler = load_model(args, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJ3ulWqzViL",
        "colab_type": "text"
      },
      "source": [
        "### Setup TensorBoard for logging experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZNieMqfzU7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
        "if not os.path.exists(tb_dir):\n",
        "  os.makedirs(tb_dir)\n",
        "writer = SummaryWriter(log_dir=tb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpl6uQiIzbvK",
        "colab_type": "text"
      },
      "source": [
        "### Create the mask that will remove correlated samples from the negative examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nik6l8ihzZ42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = mask_correlated_samples(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtNCVEynzjtV",
        "colab_type": "text"
      },
      "source": [
        "### Initialize the criterion (NT-Xent loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u067AY93zh-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = NT_Xent(args.batch_size, args.temperature, mask, args.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN5KBK-yztGD",
        "colab_type": "text"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdCrD62hzjDQ",
        "colab_type": "code",
        "outputId": "204d1e1c-7695-4714-9f2b-4e71a95352cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "args.global_step = 0\n",
        "args.current_epoch = 0\n",
        "for epoch in range(args.start_epoch, args.epochs):\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        save_model(args, model, optimizer)\n",
        "\n",
        "    writer.add_scalar(\"Loss/train\", loss_epoch / len(train_loader), epoch)\n",
        "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
        "    print(\n",
        "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
        "    )\n",
        "    args.current_epoch += 1\n",
        "\n",
        "## end training\n",
        "save_model(args, model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [0/1562]\t Loss: 4.837167263031006\n",
            "Step [50/1562]\t Loss: 4.757541656494141\n",
            "Step [100/1562]\t Loss: 4.5447211265563965\n",
            "Step [150/1562]\t Loss: 4.601693153381348\n",
            "Step [200/1562]\t Loss: 4.481614112854004\n",
            "Step [250/1562]\t Loss: 4.502140998840332\n",
            "Step [300/1562]\t Loss: 4.440523147583008\n",
            "Step [350/1562]\t Loss: 4.386401653289795\n",
            "Step [400/1562]\t Loss: 4.013962745666504\n",
            "Step [450/1562]\t Loss: 4.128726005554199\n",
            "Step [500/1562]\t Loss: 4.110790729522705\n",
            "Step [550/1562]\t Loss: 3.995676279067993\n",
            "Step [600/1562]\t Loss: 4.009866714477539\n",
            "Step [650/1562]\t Loss: 3.92177152633667\n",
            "Step [700/1562]\t Loss: 4.08205509185791\n",
            "Step [750/1562]\t Loss: 4.016186714172363\n",
            "Step [800/1562]\t Loss: 3.942352056503296\n",
            "Step [850/1562]\t Loss: 3.956094741821289\n",
            "Step [900/1562]\t Loss: 4.050191879272461\n",
            "Step [950/1562]\t Loss: 4.037079334259033\n",
            "Step [1000/1562]\t Loss: 3.8202831745147705\n",
            "Step [1050/1562]\t Loss: 3.9044482707977295\n",
            "Step [1100/1562]\t Loss: 3.985013961791992\n",
            "Step [1150/1562]\t Loss: 3.794029712677002\n",
            "Step [1200/1562]\t Loss: 3.8373451232910156\n",
            "Step [1250/1562]\t Loss: 4.060118198394775\n",
            "Step [1300/1562]\t Loss: 3.9948666095733643\n",
            "Step [1350/1562]\t Loss: 3.8218626976013184\n",
            "Step [1400/1562]\t Loss: 3.8948066234588623\n",
            "Step [1450/1562]\t Loss: 3.880082607269287\n",
            "Step [1500/1562]\t Loss: 3.9461731910705566\n",
            "Step [1550/1562]\t Loss: 3.7997963428497314\n",
            "Epoch [0/100]\t Loss: 4.09391743898697\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.878567695617676\n",
            "Step [50/1562]\t Loss: 3.837249279022217\n",
            "Step [100/1562]\t Loss: 3.7502055168151855\n",
            "Step [150/1562]\t Loss: 3.800924301147461\n",
            "Step [200/1562]\t Loss: 3.852590560913086\n",
            "Step [250/1562]\t Loss: 3.8926632404327393\n",
            "Step [300/1562]\t Loss: 3.7349190711975098\n",
            "Step [350/1562]\t Loss: 3.9932069778442383\n",
            "Step [400/1562]\t Loss: 3.837663173675537\n",
            "Step [450/1562]\t Loss: 3.886890172958374\n",
            "Step [500/1562]\t Loss: 3.7281301021575928\n",
            "Step [550/1562]\t Loss: 3.8177242279052734\n",
            "Step [600/1562]\t Loss: 3.724440097808838\n",
            "Step [650/1562]\t Loss: 3.7480480670928955\n",
            "Step [700/1562]\t Loss: 3.820406198501587\n",
            "Step [750/1562]\t Loss: 3.859227180480957\n",
            "Step [800/1562]\t Loss: 3.7451589107513428\n",
            "Step [850/1562]\t Loss: 3.7699944972991943\n",
            "Step [900/1562]\t Loss: 3.685976505279541\n",
            "Step [950/1562]\t Loss: 3.690518617630005\n",
            "Step [1000/1562]\t Loss: 3.8099236488342285\n",
            "Step [1050/1562]\t Loss: 3.725341320037842\n",
            "Step [1100/1562]\t Loss: 3.7029366493225098\n",
            "Step [1150/1562]\t Loss: 3.848743200302124\n",
            "Step [1200/1562]\t Loss: 3.8436927795410156\n",
            "Step [1250/1562]\t Loss: 3.6785855293273926\n",
            "Step [1300/1562]\t Loss: 3.7073018550872803\n",
            "Step [1350/1562]\t Loss: 3.62213397026062\n",
            "Step [1400/1562]\t Loss: 3.617572546005249\n",
            "Step [1450/1562]\t Loss: 3.657416582107544\n",
            "Step [1500/1562]\t Loss: 3.724836826324463\n",
            "Step [1550/1562]\t Loss: 3.7866451740264893\n",
            "Epoch [1/100]\t Loss: 3.7678864602090147\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.647782325744629\n",
            "Step [50/1562]\t Loss: 3.6066224575042725\n",
            "Step [100/1562]\t Loss: 3.67060923576355\n",
            "Step [150/1562]\t Loss: 3.6368203163146973\n",
            "Step [200/1562]\t Loss: 3.65976619720459\n",
            "Step [250/1562]\t Loss: 3.5929300785064697\n",
            "Step [300/1562]\t Loss: 3.6511287689208984\n",
            "Step [350/1562]\t Loss: 3.7878377437591553\n",
            "Step [400/1562]\t Loss: 3.6681740283966064\n",
            "Step [450/1562]\t Loss: 3.651473045349121\n",
            "Step [500/1562]\t Loss: 3.581507921218872\n",
            "Step [550/1562]\t Loss: 3.7855072021484375\n",
            "Step [600/1562]\t Loss: 3.669891595840454\n",
            "Step [650/1562]\t Loss: 3.605238199234009\n",
            "Step [700/1562]\t Loss: 3.691585063934326\n",
            "Step [750/1562]\t Loss: 3.62443470954895\n",
            "Step [800/1562]\t Loss: 3.6608521938323975\n",
            "Step [850/1562]\t Loss: 3.5555386543273926\n",
            "Step [900/1562]\t Loss: 3.664424419403076\n",
            "Step [950/1562]\t Loss: 3.5624947547912598\n",
            "Step [1000/1562]\t Loss: 3.6699628829956055\n",
            "Step [1050/1562]\t Loss: 3.688730478286743\n",
            "Step [1100/1562]\t Loss: 3.6050472259521484\n",
            "Step [1150/1562]\t Loss: 3.7415549755096436\n",
            "Step [1200/1562]\t Loss: 3.688659429550171\n",
            "Step [1250/1562]\t Loss: 3.667685031890869\n",
            "Step [1300/1562]\t Loss: 3.6727700233459473\n",
            "Step [1350/1562]\t Loss: 3.5892858505249023\n",
            "Step [1400/1562]\t Loss: 3.5417842864990234\n",
            "Step [1450/1562]\t Loss: 3.654776096343994\n",
            "Step [1500/1562]\t Loss: 3.616154909133911\n",
            "Step [1550/1562]\t Loss: 3.55975604057312\n",
            "Epoch [2/100]\t Loss: 3.67153831083857\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.4890644550323486\n",
            "Step [50/1562]\t Loss: 3.604285478591919\n",
            "Step [100/1562]\t Loss: 3.545543909072876\n",
            "Step [150/1562]\t Loss: 3.557795524597168\n",
            "Step [200/1562]\t Loss: 3.617588996887207\n",
            "Step [250/1562]\t Loss: 3.612175226211548\n",
            "Step [300/1562]\t Loss: 3.705768346786499\n",
            "Step [350/1562]\t Loss: 3.593222141265869\n",
            "Step [400/1562]\t Loss: 3.6797375679016113\n",
            "Step [450/1562]\t Loss: 3.640580415725708\n",
            "Step [500/1562]\t Loss: 3.6280875205993652\n",
            "Step [550/1562]\t Loss: 3.614252805709839\n",
            "Step [600/1562]\t Loss: 3.575227975845337\n",
            "Step [650/1562]\t Loss: 3.6321299076080322\n",
            "Step [700/1562]\t Loss: 3.619821786880493\n",
            "Step [750/1562]\t Loss: 3.568028688430786\n",
            "Step [800/1562]\t Loss: 3.6398651599884033\n",
            "Step [850/1562]\t Loss: 3.7337136268615723\n",
            "Step [900/1562]\t Loss: 3.6677255630493164\n",
            "Step [950/1562]\t Loss: 3.5111639499664307\n",
            "Step [1000/1562]\t Loss: 3.715071201324463\n",
            "Step [1050/1562]\t Loss: 3.6665468215942383\n",
            "Step [1100/1562]\t Loss: 3.638962984085083\n",
            "Step [1150/1562]\t Loss: 3.6388962268829346\n",
            "Step [1200/1562]\t Loss: 3.532121419906616\n",
            "Step [1250/1562]\t Loss: 3.624309539794922\n",
            "Step [1300/1562]\t Loss: 3.53464412689209\n",
            "Step [1350/1562]\t Loss: 3.564185857772827\n",
            "Step [1400/1562]\t Loss: 3.5946271419525146\n",
            "Step [1450/1562]\t Loss: 3.6118977069854736\n",
            "Step [1500/1562]\t Loss: 3.675874948501587\n",
            "Step [1550/1562]\t Loss: 3.558156967163086\n",
            "Epoch [3/100]\t Loss: 3.6196761990631434\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.6273622512817383\n",
            "Step [50/1562]\t Loss: 3.5167276859283447\n",
            "Step [100/1562]\t Loss: 3.683009624481201\n",
            "Step [150/1562]\t Loss: 3.5863277912139893\n",
            "Step [200/1562]\t Loss: 3.5580575466156006\n",
            "Step [250/1562]\t Loss: 3.510000705718994\n",
            "Step [300/1562]\t Loss: 3.490417003631592\n",
            "Step [350/1562]\t Loss: 3.756455183029175\n",
            "Step [400/1562]\t Loss: 3.514122724533081\n",
            "Step [450/1562]\t Loss: 3.528087854385376\n",
            "Step [500/1562]\t Loss: 3.4620718955993652\n",
            "Step [550/1562]\t Loss: 3.544552803039551\n",
            "Step [600/1562]\t Loss: 3.5667800903320312\n",
            "Step [650/1562]\t Loss: 3.603184461593628\n",
            "Step [700/1562]\t Loss: 3.530210018157959\n",
            "Step [750/1562]\t Loss: 3.494758129119873\n",
            "Step [800/1562]\t Loss: 3.709951400756836\n",
            "Step [850/1562]\t Loss: 3.524853467941284\n",
            "Step [900/1562]\t Loss: 3.482713222503662\n",
            "Step [950/1562]\t Loss: 3.536099672317505\n",
            "Step [1000/1562]\t Loss: 3.6588478088378906\n",
            "Step [1050/1562]\t Loss: 3.6628894805908203\n",
            "Step [1100/1562]\t Loss: 3.5296411514282227\n",
            "Step [1150/1562]\t Loss: 3.470425844192505\n",
            "Step [1200/1562]\t Loss: 3.6459851264953613\n",
            "Step [1250/1562]\t Loss: 3.5510783195495605\n",
            "Step [1300/1562]\t Loss: 3.6014652252197266\n",
            "Step [1350/1562]\t Loss: 3.540412425994873\n",
            "Step [1400/1562]\t Loss: 3.631239652633667\n",
            "Step [1450/1562]\t Loss: 3.5459346771240234\n",
            "Step [1500/1562]\t Loss: 3.608818292617798\n",
            "Step [1550/1562]\t Loss: 3.592278480529785\n",
            "Epoch [4/100]\t Loss: 3.57677677239407\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.5912373065948486\n",
            "Step [50/1562]\t Loss: 3.4798858165740967\n",
            "Step [100/1562]\t Loss: 3.565985918045044\n",
            "Step [150/1562]\t Loss: 3.5071024894714355\n",
            "Step [200/1562]\t Loss: 3.588076591491699\n",
            "Step [250/1562]\t Loss: 3.6008825302124023\n",
            "Step [300/1562]\t Loss: 3.6608171463012695\n",
            "Step [350/1562]\t Loss: 3.6050760746002197\n",
            "Step [400/1562]\t Loss: 3.4688196182250977\n",
            "Step [450/1562]\t Loss: 3.5218160152435303\n",
            "Step [500/1562]\t Loss: 3.6463255882263184\n",
            "Step [550/1562]\t Loss: 3.5665132999420166\n",
            "Step [600/1562]\t Loss: 3.62870454788208\n",
            "Step [650/1562]\t Loss: 3.523228406906128\n",
            "Step [700/1562]\t Loss: 3.5518901348114014\n",
            "Step [750/1562]\t Loss: 3.4846866130828857\n",
            "Step [800/1562]\t Loss: 3.475797414779663\n",
            "Step [850/1562]\t Loss: 3.5578560829162598\n",
            "Step [900/1562]\t Loss: 3.5532593727111816\n",
            "Step [950/1562]\t Loss: 3.6145811080932617\n",
            "Step [1000/1562]\t Loss: 3.552809715270996\n",
            "Step [1050/1562]\t Loss: 3.575915575027466\n",
            "Step [1100/1562]\t Loss: 3.6549203395843506\n",
            "Step [1150/1562]\t Loss: 3.624525785446167\n",
            "Step [1200/1562]\t Loss: 3.5080654621124268\n",
            "Step [1250/1562]\t Loss: 3.605769157409668\n",
            "Step [1300/1562]\t Loss: 3.548896551132202\n",
            "Step [1350/1562]\t Loss: 3.5418801307678223\n",
            "Step [1400/1562]\t Loss: 3.604597330093384\n",
            "Step [1450/1562]\t Loss: 3.515087366104126\n",
            "Step [1500/1562]\t Loss: 3.3884174823760986\n",
            "Step [1550/1562]\t Loss: 3.480771780014038\n",
            "Epoch [5/100]\t Loss: 3.542257130069708\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.497823476791382\n",
            "Step [50/1562]\t Loss: 3.42297101020813\n",
            "Step [100/1562]\t Loss: 3.524693489074707\n",
            "Step [150/1562]\t Loss: 3.531881332397461\n",
            "Step [200/1562]\t Loss: 3.5048105716705322\n",
            "Step [250/1562]\t Loss: 3.628197431564331\n",
            "Step [300/1562]\t Loss: 3.6306395530700684\n",
            "Step [350/1562]\t Loss: 3.451866865158081\n",
            "Step [400/1562]\t Loss: 3.5474555492401123\n",
            "Step [450/1562]\t Loss: 3.56791090965271\n",
            "Step [500/1562]\t Loss: 3.531996011734009\n",
            "Step [550/1562]\t Loss: 3.4996531009674072\n",
            "Step [600/1562]\t Loss: 3.4781124591827393\n",
            "Step [650/1562]\t Loss: 3.5710065364837646\n",
            "Step [700/1562]\t Loss: 3.5214998722076416\n",
            "Step [750/1562]\t Loss: 3.5828285217285156\n",
            "Step [800/1562]\t Loss: 3.473308801651001\n",
            "Step [850/1562]\t Loss: 3.480484962463379\n",
            "Step [900/1562]\t Loss: 3.540785789489746\n",
            "Step [950/1562]\t Loss: 3.5587122440338135\n",
            "Step [1000/1562]\t Loss: 3.4951231479644775\n",
            "Step [1050/1562]\t Loss: 3.478750705718994\n",
            "Step [1100/1562]\t Loss: 3.469435453414917\n",
            "Step [1150/1562]\t Loss: 3.5276312828063965\n",
            "Step [1200/1562]\t Loss: 3.5162298679351807\n",
            "Step [1250/1562]\t Loss: 3.559847354888916\n",
            "Step [1300/1562]\t Loss: 3.510974407196045\n",
            "Step [1350/1562]\t Loss: 3.547567367553711\n",
            "Step [1400/1562]\t Loss: 3.5530664920806885\n",
            "Step [1450/1562]\t Loss: 3.560962677001953\n",
            "Step [1500/1562]\t Loss: 3.463777542114258\n",
            "Step [1550/1562]\t Loss: 3.570962905883789\n",
            "Epoch [6/100]\t Loss: 3.5180104810663435\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.4799067974090576\n",
            "Step [50/1562]\t Loss: 3.4274868965148926\n",
            "Step [100/1562]\t Loss: 3.575655698776245\n",
            "Step [150/1562]\t Loss: 3.4906675815582275\n",
            "Step [200/1562]\t Loss: 3.507354497909546\n",
            "Step [250/1562]\t Loss: 3.5563573837280273\n",
            "Step [300/1562]\t Loss: 3.5341920852661133\n",
            "Step [350/1562]\t Loss: 3.469820499420166\n",
            "Step [400/1562]\t Loss: 3.559926748275757\n",
            "Step [450/1562]\t Loss: 3.5416243076324463\n",
            "Step [500/1562]\t Loss: 3.558910369873047\n",
            "Step [550/1562]\t Loss: 3.399467706680298\n",
            "Step [600/1562]\t Loss: 3.442542791366577\n",
            "Step [650/1562]\t Loss: 3.4399755001068115\n",
            "Step [700/1562]\t Loss: 3.5619442462921143\n",
            "Step [750/1562]\t Loss: 3.4734621047973633\n",
            "Step [800/1562]\t Loss: 3.421837091445923\n",
            "Step [850/1562]\t Loss: 3.639833688735962\n",
            "Step [900/1562]\t Loss: 3.529256582260132\n",
            "Step [950/1562]\t Loss: 3.50510311126709\n",
            "Step [1000/1562]\t Loss: 3.5558488368988037\n",
            "Step [1050/1562]\t Loss: 3.48787522315979\n",
            "Step [1100/1562]\t Loss: 3.644500255584717\n",
            "Step [1150/1562]\t Loss: 3.476858615875244\n",
            "Step [1200/1562]\t Loss: 3.603313684463501\n",
            "Step [1250/1562]\t Loss: 3.501481533050537\n",
            "Step [1300/1562]\t Loss: 3.455212116241455\n",
            "Step [1350/1562]\t Loss: 3.543229341506958\n",
            "Step [1400/1562]\t Loss: 3.4786269664764404\n",
            "Step [1450/1562]\t Loss: 3.5133707523345947\n",
            "Step [1500/1562]\t Loss: 3.5443170070648193\n",
            "Step [1550/1562]\t Loss: 3.486114978790283\n",
            "Epoch [7/100]\t Loss: 3.4983251743524235\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.493427038192749\n",
            "Step [50/1562]\t Loss: 3.567566394805908\n",
            "Step [100/1562]\t Loss: 3.491608142852783\n",
            "Step [150/1562]\t Loss: 3.557032346725464\n",
            "Step [200/1562]\t Loss: 3.4594216346740723\n",
            "Step [250/1562]\t Loss: 3.5089330673217773\n",
            "Step [300/1562]\t Loss: 3.5250794887542725\n",
            "Step [350/1562]\t Loss: 3.4256396293640137\n",
            "Step [400/1562]\t Loss: 3.5338127613067627\n",
            "Step [450/1562]\t Loss: 3.4609692096710205\n",
            "Step [500/1562]\t Loss: 3.4189586639404297\n",
            "Step [550/1562]\t Loss: 3.3869519233703613\n",
            "Step [600/1562]\t Loss: 3.4605934619903564\n",
            "Step [650/1562]\t Loss: 3.4567065238952637\n",
            "Step [700/1562]\t Loss: 3.430962324142456\n",
            "Step [750/1562]\t Loss: 3.471161127090454\n",
            "Step [800/1562]\t Loss: 3.4461793899536133\n",
            "Step [850/1562]\t Loss: 3.4736392498016357\n",
            "Step [900/1562]\t Loss: 3.5193865299224854\n",
            "Step [950/1562]\t Loss: 3.5512123107910156\n",
            "Step [1000/1562]\t Loss: 3.492849111557007\n",
            "Step [1050/1562]\t Loss: 3.4778451919555664\n",
            "Step [1100/1562]\t Loss: 3.5269339084625244\n",
            "Step [1150/1562]\t Loss: 3.4621496200561523\n",
            "Step [1200/1562]\t Loss: 3.447482109069824\n",
            "Step [1250/1562]\t Loss: 3.4294686317443848\n",
            "Step [1300/1562]\t Loss: 3.529949188232422\n",
            "Step [1350/1562]\t Loss: 3.5548646450042725\n",
            "Step [1400/1562]\t Loss: 3.4390530586242676\n",
            "Step [1450/1562]\t Loss: 3.423043966293335\n",
            "Step [1500/1562]\t Loss: 3.539119243621826\n",
            "Step [1550/1562]\t Loss: 3.5016837120056152\n",
            "Epoch [8/100]\t Loss: 3.4800668466411695\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.6394972801208496\n",
            "Step [50/1562]\t Loss: 3.4361164569854736\n",
            "Step [100/1562]\t Loss: 3.4482860565185547\n",
            "Step [150/1562]\t Loss: 3.506178140640259\n",
            "Step [200/1562]\t Loss: 3.4262986183166504\n",
            "Step [250/1562]\t Loss: 3.45479416847229\n",
            "Step [300/1562]\t Loss: 3.459824800491333\n",
            "Step [350/1562]\t Loss: 3.412548780441284\n",
            "Step [400/1562]\t Loss: 3.485488176345825\n",
            "Step [450/1562]\t Loss: 3.5215673446655273\n",
            "Step [500/1562]\t Loss: 3.467102527618408\n",
            "Step [550/1562]\t Loss: 3.4329476356506348\n",
            "Step [600/1562]\t Loss: 3.528350353240967\n",
            "Step [650/1562]\t Loss: 3.411759853363037\n",
            "Step [700/1562]\t Loss: 3.4540579319000244\n",
            "Step [750/1562]\t Loss: 3.437124252319336\n",
            "Step [800/1562]\t Loss: 3.423539400100708\n",
            "Step [850/1562]\t Loss: 3.4894754886627197\n",
            "Step [900/1562]\t Loss: 3.447507619857788\n",
            "Step [950/1562]\t Loss: 3.4133100509643555\n",
            "Step [1000/1562]\t Loss: 3.4656598567962646\n",
            "Step [1050/1562]\t Loss: 3.4622740745544434\n",
            "Step [1100/1562]\t Loss: 3.445495128631592\n",
            "Step [1150/1562]\t Loss: 3.4336838722229004\n",
            "Step [1200/1562]\t Loss: 3.3981757164001465\n",
            "Step [1250/1562]\t Loss: 3.4690072536468506\n",
            "Step [1300/1562]\t Loss: 3.5393688678741455\n",
            "Step [1350/1562]\t Loss: 3.442586898803711\n",
            "Step [1400/1562]\t Loss: 3.4547977447509766\n",
            "Step [1450/1562]\t Loss: 3.442049264907837\n",
            "Step [1500/1562]\t Loss: 3.399099826812744\n",
            "Step [1550/1562]\t Loss: 3.4517552852630615\n",
            "Epoch [9/100]\t Loss: 3.467713926268906\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.4376702308654785\n",
            "Step [50/1562]\t Loss: 3.380934000015259\n",
            "Step [100/1562]\t Loss: 3.5420029163360596\n",
            "Step [150/1562]\t Loss: 3.382063388824463\n",
            "Step [200/1562]\t Loss: 3.4543838500976562\n",
            "Step [250/1562]\t Loss: 3.5372815132141113\n",
            "Step [300/1562]\t Loss: 3.458367109298706\n",
            "Step [350/1562]\t Loss: 3.36668062210083\n",
            "Step [400/1562]\t Loss: 3.4643499851226807\n",
            "Step [450/1562]\t Loss: 3.4107253551483154\n",
            "Step [500/1562]\t Loss: 3.4467828273773193\n",
            "Step [550/1562]\t Loss: 3.48032283782959\n",
            "Step [600/1562]\t Loss: 3.3732800483703613\n",
            "Step [650/1562]\t Loss: 3.453972578048706\n",
            "Step [700/1562]\t Loss: 3.400297164916992\n",
            "Step [750/1562]\t Loss: 3.455705165863037\n",
            "Step [800/1562]\t Loss: 3.4333455562591553\n",
            "Step [850/1562]\t Loss: 3.488433599472046\n",
            "Step [900/1562]\t Loss: 3.4616353511810303\n",
            "Step [950/1562]\t Loss: 3.3690602779388428\n",
            "Step [1000/1562]\t Loss: 3.465308904647827\n",
            "Step [1050/1562]\t Loss: 3.424433469772339\n",
            "Step [1100/1562]\t Loss: 3.4302124977111816\n",
            "Step [1150/1562]\t Loss: 3.4509189128875732\n",
            "Step [1200/1562]\t Loss: 3.5307886600494385\n",
            "Step [1250/1562]\t Loss: 3.3838605880737305\n",
            "Step [1300/1562]\t Loss: 3.40140438079834\n",
            "Step [1350/1562]\t Loss: 3.4364917278289795\n",
            "Step [1400/1562]\t Loss: 3.4281513690948486\n",
            "Step [1450/1562]\t Loss: 3.5009682178497314\n",
            "Step [1500/1562]\t Loss: 3.3653647899627686\n",
            "Step [1550/1562]\t Loss: 3.4776227474212646\n",
            "Epoch [10/100]\t Loss: 3.452187482587201\t lr: 0.0003\n",
            "Step [0/1562]\t Loss: 3.4683971405029297\n",
            "Step [50/1562]\t Loss: 3.3699464797973633\n",
            "Step [100/1562]\t Loss: 3.4413583278656006\n",
            "Step [150/1562]\t Loss: 3.42010235786438\n",
            "Step [200/1562]\t Loss: 3.431398630142212\n",
            "Step [250/1562]\t Loss: 3.405012607574463\n",
            "Step [300/1562]\t Loss: 3.4471733570098877\n",
            "Step [350/1562]\t Loss: 3.4479782581329346\n",
            "Step [400/1562]\t Loss: 3.3999557495117188\n",
            "Step [450/1562]\t Loss: 3.4584155082702637\n",
            "Step [500/1562]\t Loss: 3.4325075149536133\n",
            "Step [550/1562]\t Loss: 3.4122700691223145\n",
            "Step [600/1562]\t Loss: 3.5206875801086426\n",
            "Step [650/1562]\t Loss: 3.5392355918884277\n",
            "Step [700/1562]\t Loss: 3.409726858139038\n",
            "Step [750/1562]\t Loss: 3.4477460384368896\n",
            "Step [800/1562]\t Loss: 3.3349499702453613\n",
            "Step [850/1562]\t Loss: 3.454132556915283\n",
            "Step [900/1562]\t Loss: 3.5409579277038574\n",
            "Step [950/1562]\t Loss: 3.3496901988983154\n",
            "Step [1000/1562]\t Loss: 3.507133722305298\n",
            "Step [1050/1562]\t Loss: 3.435131072998047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77BXUR9_4hNc",
        "colab_type": "text"
      },
      "source": [
        "## Download last checkpoint to local drive (replace `100` with `args.epochs`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7eHATk04Sgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./logs/checkpoint_100.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAQpjiuJy61N",
        "colab_type": "text"
      },
      "source": [
        "# Part 2:\n",
        "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24wrzMP2vYcV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFyS9RvpuCuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "\n",
        "from experiment import ex\n",
        "from model import load_model\n",
        "from utils import post_config_hook\n",
        "\n",
        "from modules import LogisticRegression\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZRtPBCLvgqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
        "    loss_epoch = 0\n",
        "    accuracy_epoch = 0\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = x.to(args.device)\n",
        "        y = y.to(args.device)\n",
        "\n",
        "        # get encoding\n",
        "        with torch.no_grad():\n",
        "            h, z = simclr_model(x)\n",
        "            # h = 512\n",
        "            # z = 64\n",
        "\n",
        "        output = model(h)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        predicted = output.argmax(1)\n",
        "        acc = (predicted == y).sum().item() / y.size(0)\n",
        "        accuracy_epoch += acc\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "        if step % 1 == 0:\n",
        "            print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\")\n",
        "\n",
        "    return loss_epoch, accuracy_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skBYAPb2uKB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
        "    loss_epoch = 0\n",
        "    accuracy_epoch = 0\n",
        "    model.eval()\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        model.zero_grad()\n",
        "\n",
        "        x = x.to(args.device)\n",
        "        y = y.to(args.device)\n",
        "\n",
        "        # get encoding\n",
        "        with torch.no_grad():\n",
        "            h, z = simclr_model(x)\n",
        "            # h = 512\n",
        "            # z = 64\n",
        "\n",
        "        output = model(h)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        predicted = output.argmax(1)\n",
        "        acc = (predicted == y).sum().item() / y.size(0)\n",
        "        accuracy_epoch += acc\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "\n",
        "\n",
        "    return loss_epoch, accuracy_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJk4-nc-vkF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "from utils.yaml_config_hook import yaml_config_hook\n",
        "\n",
        "config = yaml_config_hook(\"./config/config.yaml\")\n",
        "pprint(config)\n",
        "args = argparse.Namespace(**config)\n",
        "\n",
        "if use_tpu:\n",
        "  args.device = dev\n",
        "else:\n",
        "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7cSwhu55KJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args.batch_size = 64\n",
        "args.resnet = \"resnet18\"\n",
        "args.model_path = \"logs\"\n",
        "args.epoch_num = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWRuVrZZ5Vm1",
        "colab_type": "text"
      },
      "source": [
        "### Load dataset into train/test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPGuFjLW5PF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"./datasets\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "if args.dataset == \"STL10\":\n",
        "    train_dataset = torchvision.datasets.STL10(\n",
        "        root, split=\"train\", download=True, transform=torchvision.transforms.ToTensor()\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.STL10(\n",
        "        root, split=\"test\", download=True, transform=torchvision.transforms.ToTensor()\n",
        "    )\n",
        "elif args.dataset == \"CIFAR10\":\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root, train=True, download=True, transform=transform\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root, train=False, download=True, transform=transform\n",
        "    )\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.logistic_batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=args.logistic_batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmwXqVBH5ZX6",
        "colab_type": "text"
      },
      "source": [
        "### Load SimCLR model and load model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTVnvx2a5QnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
        "simclr_model = simclr_model.to(args.device)\n",
        "simclr_model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZoABGRr5Q8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Logistic Regression\n",
        "n_classes = 10 # stl-10\n",
        "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
        "model = model.to(args.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T694n_HQ5Tad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLaebM9Qvztx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(args.logistic_epochs):\n",
        "    loss_epoch, accuracy_epoch = train(args, train_loader, simclr_model, model, criterion, optimizer)\n",
        "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
        "\n",
        "# final testing\n",
        "loss_epoch, accuracy_epoch = test(args, test_loader, simclr_model, model, criterion, optimizer)\n",
        "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}