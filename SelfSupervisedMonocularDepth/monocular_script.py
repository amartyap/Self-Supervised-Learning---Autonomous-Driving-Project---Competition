# -*- coding: utf-8 -*-
"""monocular_script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17aLCV2QoM9KgA_OGDDL26Ipv408vMCU-
"""

from google.colab import drive
drive.mount('/data/')
from pathlib import Path
base_dir = ('/data/My Drive')

!git clone https://github.com/AmeerHamza111/SimCLR.git

#!cp  /data/My\ Drive/DeepLearning/student_data.zip /content/SimCLR

#!cp -r /data/My\ Drive/DeepLearning/networks /content/SimCLR

#!cp -r /data/My\ Drive/DeepLearning/models /content/SimCLR

#!unzip student_data.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd SimCLR

def LoadDepthModels(image_name, image):
        modelsDict = {'CAM_BACK.jpeg': 'monoback', 'CAM_FRONT.jpeg': 'monofront', 
        'CAM_FRONT_LEFT.jpeg': 'monofrontleft', 'CAM_FRONT_RIGHT.jpeg' : 'monofrontright',
        'CAM_BACK_LEFT.jpeg': 'monobackleft', 'CAM_BACK_RIGHT.jpeg': 'monobackright'}
        model_path = os.path.join("models", modelsDict[image_name])
        #print("-> Loading model from ", model_path)
        encoder_path = os.path.join(model_path, "encoder.pth")
        depth_decoder_path = os.path.join(model_path, "depth.pth")
        #device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        device = "cuda"


        # LOADING PRETRAINED MODEL
        #print("Loading pretrained encoder")
        encoder = networks.ResnetEncoder(18, False)
        loaded_dict_enc = torch.load(encoder_path)

        # extract the height and width of image that this model was trained with
        feed_height = loaded_dict_enc['height']
        feed_width = loaded_dict_enc['width']
        filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}
        encoder.load_state_dict(filtered_dict_enc)
        encoder.to(device)
        encoder.eval()

        #print("Loading pretrained decoder")
        depth_decoder = networks.DepthDecoder(num_ch_enc=encoder.num_ch_enc, scales=range(4))

        loaded_dict = torch.load(depth_decoder_path)
        depth_decoder.load_state_dict(loaded_dict)

        depth_decoder.to(device)
        depth_decoder.eval()


        original_width, original_height = image.size
        input_image = image.resize((feed_width, feed_height), Image.LANCZOS)
        input_image = transforms.ToTensor()(input_image).unsqueeze(0)

        input_image = input_image.to(device)
        features = encoder(input_image)
        outputs = depth_decoder(features)

        disp = outputs[("disp", 0)]
        disp_resized = torch.nn.functional.interpolate(
                disp, (original_height, original_width), mode="bilinear", align_corners=False)
        #print(disp_resized.shape)
        _, depth = disp_to_depth(disp_resized, 0.1, 100)
        #print(depth.shape) 
        #print(type(depth.squeeze(0)))  
        return depth.squeeze(0)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import transforms, datasets

import fnmatch
import os

import os
from PIL import Image

import numpy as np
import pandas as pd



import networks
from layers import disp_to_depth, BackprojectDepth, ProjectTV

from pathlib import Path


rootPath = 'data'
pattern = 'CAM_FRONT_LEFT.jpeg'
savefile = F"/data/My Drive/DeepLearning/data"
fn = []
 
for root, dirs, files in os.walk(rootPath):
  for filename in fnmatch.filter(files, pattern):
    print(os.path.join(root, filename))
    print(root)
    image = Image.open(os.path.join(root, filename))
    iim = LoadDepthModels(pattern, image)
    #print(iim.detach().cpu().numpy())
    Path(os.path.join(savefile,root)).mkdir(parents=True, exist_ok=True)
    name_dest_npy = os.path.join(os.path.join(savefile,root), filename+"_d.npy")
    np.save(name_dest_npy, iim.detach().cpu().numpy())
    fn.append(os.path.join(root, filename))
    #b = np.load(name_dest_npy)
    #print("****")
    #print(b)